# -*- coding: utf-8 -*-
"""Copy of Copy of Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FR5nwY3L7OP722CNsK3HPY1NyAIDa1lG
"""

#to access kaggle datasets
!pip install kaggle
#Math operations
!pip install numpy==1.15.0
#Machine learning
!pip install catboost

#data preprocessing
import pandas as pd
#math operations
import numpy as np
#machine learning
#from catboost import CatBoostRegressor, Pool
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.tree import export_graphviz
#import pydot
#data scaling
from sklearn.preprocessing import StandardScaler
#hyperparameter optimization
from sklearn.model_selection import GridSearchCV
#support vector machine model
from sklearn.svm import NuSVR, SVR
#kernel ridge model
from sklearn.kernel_ridge import KernelRidge
#data visualization
import matplotlib.pyplot as plt

# Colab's file access feature
from google.colab import files

#retrieve uploaded file
uploaded = files.upload()

#print results
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

#list competitions
!kaggle competitions list

#download earthquake data, will take 30-60 seconds
!kaggle competitions download -c LANL-Earthquake-Prediction

#Extract training data into a dataframe for further manipulation
train = pd.read_csv('train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})

!ls
!unzip train.csv.zip
!ls

train_df = pd.read_csv('train.csv', nrows=6000000, iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})

train_ad_sample_df = []
train_ttf_sample_df = []

for tdf in train_df:
    #print(tdf)
    train_ad_sample_df.append(tdf['acoustic_data'].values[::100])
    train_ttf_sample_df.append(tdf['time_to_failure'].values[::100])
#print('The shape of our features is:', train_df.shape)

def gen_features(X):
    strain = []
    strain.append(X.mean())
    strain.append(X.std())
    strain.append(X.min())
    strain.append(X.max())
    strain.append(X.kurtosis())
    strain.append(X.skew())
    #strain.append(np.quantile(X,0.01))
    #strain.append(pd.quantile(X,0.25))
    #strain.append(np.quantile(X,0.75))
    #strain.append(np.quantile(X,0.50))
    strain.append(np.abs(X).max())
    strain.append(np.abs(X).mean())
    strain.append(np.abs(X).std())
    return pd.Series(strain)

X_train = pd.DataFrame()
y_train = pd.Series()
for df in train_df:
    ch = gen_features(df['acoustic_data'])
    X_train = X_train.append(ch, ignore_index=True)
    y_train = y_train.append(pd.Series(df['time_to_failure'].values[-1]))

X_train, X_test, y_train, y_test = train_test_split(train_ad_sample_df, train_ttf_sample_df, test_size=0.2, random_state=0)

sc = StandardScaler()  
X_train = sc.fit_transform(X_train)  
X_test = sc.transform(X_test)

regressor = RandomForestRegressor(n_estimators= 1000, random_state=0)  
regressor.fit(X_train, y_train)

from sklearn import metrics
y_pred = regressor.predict(X_test) 
print(y_pred)
#print("\nX_train:\n")
#print(X_train.head())
#print(X_train.shape)

#print("\nX_test:\n")
#print(X_test.head())
#print(X_test.shape)

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#print first 10 entries
train.head(10)

#visualize 1% of samples data, first 100 datapoints
train_ad_sample_df = train['acoustic_data'].values[::100]
train_ttf_sample_df = train['time_to_failure'].values[::100]

#function for plotting based on both features
def plot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df, title="Acoustic data and time to failure: 1% sampled data"):
    fig, ax1 = plt.subplots(figsize=(12, 8))
    plt.title(title)
    plt.plot(train_ad_sample_df, color='r')
    ax1.set_ylabel('acoustic data', color='r')
    plt.legend(['acoustic data'], loc=(0.01, 0.95))
    ax2 = ax1.twinx()
    plt.plot(train_ttf_sample_df, color='b')
    ax2.set_ylabel('time to failure', color='b')
    plt.legend(['time to failure'], loc=(0.01, 0.9))
    plt.grid(True)

plot_acc_ttf_data(train_ad_sample_df, train_ttf_sample_df)
#del train_ad_sample_df
#del train_ttf_sample_df

bin_list = np.linspace(min(train_ad_sample_df),max(train_ad_sample_df),5)
print(bin_list)

plt.hist(train_ad_sample_df, bins=bin_list)

#min_sam_x = min(train_ad_sample_df)
#max_sam_x = max(train_ad_sample_df)
train_sample_2 = [x for x in train_ad_sample_df if x <=-200 or 200 <= x ]

bin_list_2 = np.linspace(min(train_sample_2),max(train_sample_2),30)
plt.hist(train_sample_2, bins=bin_list_2)

x, y = np.random.random((2, 10))
sample_train_ttf = train_ttf_sample_df[1:100]
min_sm = min(sample_train_ttf)
max_sm = max(sample_train_ttf)
rgb = (sample_train_ttf - min_sm)/ (max_sm - min_sm)
print(sample_train_ttf)
#rgb = np.random.random((10, 3))
#print(rgb)
fig, ax = plt.subplots()
#ax.scatter(x, y,c='0.1',)
ax.scatter(x,y, c=rgb,marker = 's',  cmap=cm.Greys)
plt.gray()

plt.show()

!ls

!mkdir test
!ls
!mv test.zip test
# %cd test
!ls
!unzip test.zip
# %cd ..

test_seg_430e66 = pd.read_csv('test/seg_430e66.csv', dtype={'acoustic_data': np.int16})

#visualize 1% of samples data, first 100 datapoints
test_sample = test_seg_430e66['acoustic_data'].values[::]


#function for plotting based on both features
def plot_acc_ttf_data(train_ad_sample_df,  title="Acoustic data of seg_430e66"):
    fig, ax1 = plt.subplots(figsize=(12, 8))
    plt.title(title)
    plt.plot(train_ad_sample_df, color='r')
    ax1.set_ylabel('acoustic data', color='r')
    plt.legend(['acoustic data'], loc=(0.01, 0.95))
    plt.grid(True)

plot_acc_ttf_data(test_sample)
#del test_sample

#bin_list = np.linspace(min(test_sample),max(test_sample),13)
#print(bin_list)
#plt.hist(test_sample, bins=bin_list)

min_sam = min(test_sample)
max_sam = max(test_sample)
test_sample_2 = [x for x in test_sample if min_sam  <= x <=-30 or 40 <= x <= max_sam]

bin_list = np.linspace(min(test_sample_2),max(test_sample_2),20)
#print(bin_list)
plt.hist(test_sample_2, bins=bin_list)

def gen_features(X):
    strain = []
    strain.append(X.mean())
    strain.append(X.std())
    strain.append(X.min())
    strain.append(X.max())
    strain.append(X.kurtosis())
    strain.append(X.skew())
    strain.append(np.quantile(X,0.01))
    strain.append(np.quantile(X,0.05))
    strain.append(np.quantile(X,0.95))
    strain.append(np.quantile(X,0.99))
    strain.append(np.abs(X).max())
    strain.append(np.abs(X).mean())
    strain.append(np.abs(X).std())
    return pd.Series(strain)

!pip install numpy==1.15.0
np.quantile

train = pd.read_csv('train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})

X_train = pd.DataFrame()
y_train = pd.Series()
for df in train:
    ch = gen_features(df['acoustic_data'])
    X_train = X_train.append(ch, ignore_index=True)
    y_train = y_train.append(pd.Series(df['time_to_failure'].values[-1]))